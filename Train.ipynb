{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from newencoder import Encoder\n",
    "from newencoder import Encoder\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = \"/home/jingjing/Desktop/InferSent-master/dataset/GloVe/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n",
      "True\n",
      "None\n",
      "True\n",
      "None\n",
      "True\n",
      "None\n",
      "True\n",
      "None\n",
      "True\n",
      "None\n",
      "True\n",
      "None\n",
      "True\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "f = Encoder()\n",
    "f.set_w2v_path(W2V_PATH)\n",
    "\n",
    "f.zero_grad()\n",
    "\n",
    "for i in f.parameters():\n",
    "    i.retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(context_size, dim):\n",
    "    targets = np.zeros((dim, dim))\n",
    "    ctxt_sent_pos = list(range(-context_size, context_size+1))\n",
    "    ctxt_sent_pos.remove(0)\n",
    "    for ctxt in ctxt_sent_pos:\n",
    "        targets += np.eye(3, k=ctxt)\n",
    "    targets_sum = np.sum(targets,axis=1, keepdims=True)\n",
    "    targets = targets / targets_sum\n",
    "    targets = torch.from_numpy(targets)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_senmat(enc, sentences, bsize, tokenize, verbose):\n",
    "    enc.build_vocab(sentences, True)\n",
    "    embeddings = enc.encode(sentences, bsize, tokenize, verbose)\n",
    "    scores = np.matmul(embeddings,np.transpose(embeddings))\n",
    "    scores_sum = np.sum(scores, axis=1, keepdims=True)\n",
    "    scores = scores/scores_sum\n",
    "    scores = torch.from_numpy(scores)\n",
    "    scores.requires_grad = True\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xentropy_cost(pred, target):\n",
    "    logged = torch.log(pred)\n",
    "    a = target.float()*logged\n",
    "    cost = -torch.sum(a)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(pred, target):\n",
    "    m = nn.Softmax(dim=-1)\n",
    "    s_pred = m(pred)\n",
    "    losses = F.binary_cross_entropy_with_logits(s_pred, target)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['Memories of childhood are unforgettable.', 'I was four years old when my grandfather died.',\n",
    "             'I clearly remember how everybody in the house was weeping.'], ['Today is sunny', 'We should go out for a picnic.', 'Love the weather.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['Doctors lead a hard life.', 'Their life is very busy.', 'They get up early in the morning and go to the hospital.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23(/23) words with w2v vectors\n",
      "Vocab size : 23\n",
      "Nb words kept : 25/28 (89.3%)\n",
      "Speed : 103.3 sentences/s (cpu mode, bsize=3)\n",
      "tensor([[ 0.3544,  0.3179,  0.3277],\n",
      "        [ 0.3212,  0.3540,  0.3249],\n",
      "        [ 0.3252,  0.3191,  0.3557]])\n",
      "tensor([[ 0.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0000,  0.5000],\n",
      "        [ 0.0000,  1.0000,  0.0000]], dtype=torch.float64)\n",
      "L1Loss()\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    f.build_vocab(test, True)\n",
    "    scores = f(test, 400, False, True)\n",
    "    #scores = make_senmat(f, test, 400, False, True)\n",
    "    print(scores)\n",
    "    targets = make_target(1, 3)\n",
    "    print(targets)\n",
    "    loss = nn.L1Loss(scores, targets.float())\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(f.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3671)\n",
      "None\n",
      "tensor([[ 0.1111, -0.1111,  0.1111],\n",
      "        [-0.1111,  0.1111, -0.1111],\n",
      "        [ 0.1111, -0.1111,  0.1111]])\n",
      "0 tensor(0.3718)\n",
      "None\n",
      "tensor([[ 0.1111, -0.1111,  0.1111],\n",
      "        [-0.1111,  0.1111, -0.1111],\n",
      "        [ 0.1111, -0.1111,  0.1111]])\n",
      "1 tensor(0.3671)\n",
      "None\n",
      "tensor([[ 0.1111, -0.1111,  0.1111],\n",
      "        [-0.1111,  0.1111, -0.1111],\n",
      "        [ 0.1111, -0.1111,  0.1111]])\n",
      "1 tensor(0.3718)\n",
      "None\n",
      "tensor([[ 0.1111, -0.1111,  0.1111],\n",
      "        [-0.1111,  0.1111, -0.1111],\n",
      "        [ 0.1111, -0.1111,  0.1111]])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for instance in data:\n",
    "        f.zero_grad()\n",
    "        scores = f(instance, 400, False, False)\n",
    "        scores = Variable(scores, requires_grad=True)\n",
    "        #scores = make_senmat(f, instance, 400, False, True)\n",
    "        \n",
    "        targets = make_target(1,3)\n",
    "        loss_f = nn.L1Loss()\n",
    "        loss = loss_f(scores, targets.float())\n",
    "        print(epoch, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(list(f.parameters())[0].grad)\n",
    "        print(scores.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_gru.weight_ih_l0\n",
      "enc_gru.weight_hh_l0\n",
      "enc_gru.bias_ih_l0\n",
      "enc_gru.bias_hh_l0\n",
      "enc_gru.weight_ih_l0_reverse\n",
      "enc_gru.weight_hh_l0_reverse\n",
      "enc_gru.bias_ih_l0_reverse\n",
      "enc_gru.bias_hh_l0_reverse\n"
     ]
    }
   ],
   "source": [
    "for name, params in f.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 25/28 (89.3%)\n",
      "Speed : 77.2 sentences/s (cpu mode, bsize=400)\n",
      "tensor([[ 0.3526,  0.3160,  0.3315],\n",
      "        [ 0.3181,  0.3541,  0.3279],\n",
      "        [ 0.3233,  0.3176,  0.3591]])\n",
      "tensor([[ 0.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0000,  0.5000],\n",
      "        [ 0.0000,  1.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor(0.8333)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scores = f(test, 400, False, True)\n",
    "    print(scores)\n",
    "    targets = make_target(1, 3)\n",
    "    print(targets)\n",
    "    loss = loss_fn(scores, targets.float())\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
