{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import Encoder\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = \"/home/jingjing/Desktop/InferSent-master/dataset/GloVe/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Encoder()\n",
    "f.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(context_size, dim):\n",
    "    targets = np.zeros((dim, dim))\n",
    "    ctxt_sent_pos = list(range(-context_size, context_size+1))\n",
    "    ctxt_sent_pos.remove(0)\n",
    "    for ctxt in ctxt_sent_pos:\n",
    "        targets += np.eye(3, k=ctxt)\n",
    "    targets_sum = np.sum(targets,axis=1, keepdims=True)\n",
    "    targets = targets / targets_sum\n",
    "    targets = torch.from_numpy(targets)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_senmat(enc, sentences, bsize, tokenize, verbose):\n",
    "    enc.build_vocab(sentences, True)\n",
    "    embeddings = enc.encode(sentences, bsize, tokenize, verbose)\n",
    "    scores = np.matmul(embeddings,np.transpose(embeddings))\n",
    "    scores_sum = np.sum(scores, axis=1, keepdims=True)\n",
    "    scores = scores/scores_sum\n",
    "    scores = torch.from_numpy(scores)\n",
    "    scores.requires_grad = True\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xentropy_cost(pred, target):\n",
    "    logged = torch.log(pred)\n",
    "    a = target.float()*logged\n",
    "    cost = -torch.sum(a)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['Memories of childhood are unforgettable.', 'I was four years old when my grandfather died.',\n",
    "             'I clearly remember how everybody in the house was weeping.'], [' The Moon is filled wit craters.', 'It has no light of its own.', 'It gets its light from the Sun.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['Doctors lead a hard life.', 'Their life is very busy.', 'They get up early in the morning and go to the hospital.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23(/23) words with w2v vectors\n",
      "Vocab size : 23\n",
      "Nb words kept : 25/28 (89.3%)\n",
      "torch.Size([13, 3, 300])\n",
      "Speed : 103.0 sentences/s (cpu mode, bsize=400)\n",
      "tensor([[ 0.3544,  0.3280,  0.3176],\n",
      "        [ 0.3219,  0.3569,  0.3212],\n",
      "        [ 0.3197,  0.3294,  0.3508]])\n",
      "tensor([[ 0.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0000,  0.5000],\n",
      "        [ 0.0000,  1.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor(3.3598)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scores = make_senmat(f, test, 400, False, True)\n",
    "    print(scores)\n",
    "    targets = make_target(1, 3)\n",
    "    print(targets)\n",
    "    loss = xentropy_cost(scores, targets)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(f.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "0 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "0 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "1 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "1 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "2 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "2 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "3 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "3 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "4 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "4 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "5 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "5 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "6 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "6 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "7 tensor(3.3736)\n",
      "Found 20(/20) words with w2v vectors\n",
      "Vocab size : 20\n",
      "torch.Size([8, 3, 300])\n",
      "7 tensor(3.3448)\n",
      "Found 25(/25) words with w2v vectors\n",
      "Vocab size : 25\n",
      "torch.Size([11, 3, 300])\n",
      "8 tensor(3.3736)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f3a8edc603a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_senmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxentropy_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6183ea2e3667>\u001b[0m in \u001b[0;36mmake_senmat\u001b[0;34m(enc, sentences, bsize, tokenize, verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_senmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emb/encoder.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, tokenize)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w2v_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w2v path not set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mword_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_w2v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Vocab size : %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emb/encoder.py\u001b[0m in \u001b[0;36mget_w2v\u001b[0;34m(self, word_dict)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mword_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for instance in data:\n",
    "        f.zero_grad()\n",
    "        scores = make_senmat(f, instance, 400, False, False)\n",
    "        targets = make_target(1,3)\n",
    "        loss = xentropy_cost(scores, targets)\n",
    "        print(epoch, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23(/23) words with w2v vectors\n",
      "Vocab size : 23\n",
      "Nb words kept : 25/28 (89.3%)\n",
      "torch.Size([13, 3, 300])\n",
      "Speed : 90.1 sentences/s (cpu mode, bsize=400)\n",
      "tensor([[ 0.3544,  0.3280,  0.3176],\n",
      "        [ 0.3219,  0.3569,  0.3212],\n",
      "        [ 0.3197,  0.3294,  0.3508]])\n",
      "tensor([[ 0.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0000,  0.5000],\n",
      "        [ 0.0000,  1.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor(3.3598)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scores = make_senmat(f, test, 400, False, True)\n",
    "    print(scores)\n",
    "    targets = make_target(1, 3)\n",
    "    print(targets)\n",
    "    loss = xentropy_cost(scores, targets)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
